{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os \n",
    "\n",
    "from numpy import *\n",
    "from numpy import linalg as la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.) Load in the joke ratings data and the joke text data into appropriate data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.18, 19.79,  1.34, ...,  0.  ,  0.  ,  0.  ],\n",
       "       [15.08, 10.71, 17.36, ..., 11.34,  6.68, 12.07],\n",
       "       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "       ...,\n",
       "       [16.58, 16.63, 15.85, ...,  0.  ,  0.  ,  0.  ],\n",
       "       [ 3.67,  4.45,  3.67, ...,  3.77,  3.77,  3.28],\n",
       "       [ 9.88, 11.73,  9.16, ...,  0.  ,  0.  ,  0.  ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings  = np.genfromtxt(r\"C:\\Users\\Owner\\Documents\\DSC 478\\modified_jester_data.csv\", delimiter=',')\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes = np.genfromtxt(r\"C:\\Users\\Owner\\Documents\\DSC 478\\jokes.csv\",delimiter=',',dtype=str)\n",
    "jokes = np.array(jokes[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jokes(file):\n",
    "    jokes = genfromtxt(file, delimiter=',', dtype=str)\n",
    "    jokes = np.array(jokes[:,1])\n",
    "    return jokes\n",
    "\n",
    "def get_joke_text(jokes, id):\n",
    "\treturn jokes[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(0.2*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A man visits the doctor. The doctor says \"I have bad news for you.You have cancer and Alzheimer\\'s disease\". The man replies \"Well thank God I don\\'t have cancer!\"',\n",
       "       'This couple had an excellent relationship going until one day he came home from work to find his girlfriend packing. He asked her why she was leaving him and she told him that she had heard awful things about him. \"What could they possibly have said to make you move out?\" \"They told me that you were a pedophile.\" He replied \"That\\'s an awfully big word for a ten year old.\"',\n",
       "       \"Q. What's 200 feet long and has 4 teeth? A. The front row at a Willie Nelson Concert.\",\n",
       "       \"Q. What's the difference between a man and a toilet? A. A toilet doesn't follow you around after you use it.\",\n",
       "       \"Q. What's O. J. Simpson's Internet address? A.\\tSlash slash backslash slash slash escape.\"],\n",
       "      dtype='<U1198')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokes[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' See example output below:\\n\\nSelected joke: \\n\\nQ. What\\'s the difference between a man and a toilet? A. A toilet doesn\\'t follow you around after you use it.\\n\\nTop 5 Recommended jokes are :\\n\\nQ: What\\'s the difference between a Lawyer and a Plumber? A: A Plumber works to unclog the system. \\n_______________\\nWhat do you call an American in the finals of the world cup? \"Hey Beer Man!\" \\n_______________\\nQ. What\\'s 200 feet long and has 4 teeth? <P>A. The front row at a Willie Nelson Concert. \\n_______________\\nA country guy goes into a city bar that has a dress code and the maitred\\' demands he wear a tie. Discouraged the guy goes to his car to sulk when inspiration strikes: He\\'s got jumper cables in the trunk! So he wrapsthem around his neck sort of like a string tie (a bulky string tie to be sure) and returns to the bar. The maitre d\\' is reluctant but says to the guy \"Okay you\\'re a pretty resourceful fellow you can come in... but just don\\'t start anything\"!   \\n_______________\\nWhat do you get when you run over a parakeet with a lawnmower? <P>Shredded tweet. \\n_______________\\n\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ecludSim(inA,inB):\n",
    "    return 1.0 / (1.0 + la.norm(inA - inB))\n",
    "\n",
    "def pearsSim(inA,inB):\n",
    "    if len(inA) < 3 : return 1.0\n",
    "    return 0.5 + 0.5 * corrcoef(inA, inB, rowvar = 0)[0][1]\n",
    "\n",
    "def cosSim(inA,inB):\n",
    "    num = float(inA.T * inB)\n",
    "    denom = la.norm(inA)*la.norm(inB)\n",
    "    return 0.5 + 0.5 * (num / denom)\n",
    "\n",
    "def standEst(dataMat, user, simMeas, item):\n",
    "    n = shape(dataMat)[1]\n",
    "    simTotal = 0.0; ratSimTotal = 0.0\n",
    "    for j in range(n):\n",
    "        userRating = dataMat[user,j]\n",
    "        if userRating == 0: continue\n",
    "        overLap = nonzero(logical_and(dataMat[:,item]>0, \\\n",
    "                                      dataMat[:,j]>0))[0]\n",
    "        if len(overLap) == 0: similarity = 0\n",
    "        else: similarity = simMeas(dataMat[overLap,item], \\\n",
    "                                   dataMat[overLap,j])\n",
    "        #print 'the %d and %d similarity is: %f' % (item, j, similarity)\n",
    "        simTotal += similarity\n",
    "        ratSimTotal += similarity * userRating\n",
    "    if simTotal == 0: return 0\n",
    "    else: return ratSimTotal/simTotal\n",
    "    \n",
    "def svdEst(dataMat, user, simMeas, item):\n",
    "    n = shape(dataMat)[1]\n",
    "    simTotal = 0.0; ratSimTotal = 0.0\n",
    "    data=mat(dataMat)\n",
    "    U,Sigma,VT = la.svd(data)\n",
    "    Sig4 = mat(eye(4)*Sigma[:4]) #arrange Sig4 into a diagonal matrix\n",
    "    xformedItems = data.T * U[:,:4] * Sig4.I  #create transformed items\n",
    "    for j in range(n):\n",
    "        userRating = data[user,j]\n",
    "        if userRating == 0 or j==item: continue\n",
    "        similarity = simMeas(xformedItems[item,:].T,\\\n",
    "                             xformedItems[j,:].T)\n",
    "        #print 'the %d and %d similarity is: %f' % (item, j, similarity)\n",
    "        simTotal += similarity\n",
    "        ratSimTotal += similarity * userRating\n",
    "    if simTotal == 0: return 0\n",
    "    else: return ratSimTotal/simTotal\n",
    "\n",
    "# This function is not needed for Assignment 4, but may be useful for experimentation\n",
    "def recommend(dataMat, user, N=3, simMeas=cosSim, estMethod=standEst):\n",
    "    unratedItems = nonzero(dataMat[user,:].A==0)[1] #find unrated items \n",
    "    if len(unratedItems) == 0: return 'you rated everything'\n",
    "    itemScores = []\n",
    "    for item in unratedItems:\n",
    "        estimatedScore = estMethod(dataMat, user, simMeas, item)\n",
    "        itemScores.append((item, estimatedScore))\n",
    "    return sorted(itemScores, key=lambda jj: jj[1], reverse=True)[:N]\n",
    "\n",
    "# This function performs evaluatoin on a single user based on the test_ratio\n",
    "# For example, with test_ratio = 0.2, a randomly selected 20 percent of rated \n",
    "# items by the user are withheld and the rest are used to estimate the withheld ratings\n",
    "\n",
    "def cross_validate_user(dataMat, user, test_ratio, estMethod=standEst, simMeas=pearsSim):\n",
    "\tnumber_of_items = np.shape(dataMat)[1]\n",
    "\trated_items_by_user = np.array([i for i in range(number_of_items) if dataMat[user,i]>0])\n",
    "\ttest_size = test_ratio * len(rated_items_by_user)\n",
    "\ttest_indices = np.random.randint(0, len(rated_items_by_user), test_size)\n",
    "\twithheld_items = rated_items_by_user[test_indices]\n",
    "\toriginal_user_profile = np.copy(dataMat[user])\n",
    "\tdataMat[user, withheld_items] = 0 # So that the withheld test items is not used in the rating estimation below\n",
    "\terror_u = 0.0\n",
    "\tcount_u = len(withheld_items)\n",
    "\n",
    "\t# Compute absolute error for user u over all test items\n",
    "\tfor item in withheld_items:\n",
    "\t\t# Estimate rating on the withheld item\n",
    "\t\testimatedScore = estMethod(dataMat, user, simMeas, item)\n",
    "\t\terror_u = error_u + abs(estimatedScore - original_user_profile[item])\t\n",
    "\t\n",
    "\t# Now restore ratings of the withheld items to the user profile\n",
    "\tfor item in withheld_items:\n",
    "\t\tdataMat[user, item] = original_user_profile[item]\n",
    "\t\t\n",
    "\t# Return sum of absolute errors and the count of test cases for this user\n",
    "\t# Note that these will have to be accumulated for each user to compute MAE\n",
    "\treturn error_u, count_u\n",
    "\t\n",
    "def test(dataMat, test_ratio, estMethod):\n",
    "    # Write this function to iterate over all users and for each perform evaluation by calling\n",
    "\t# the above cross_validate_user function on each user. MAE will be the ratio of total error \n",
    "\t# across all test cases to the total number of test cases, for all users\n",
    "\tprint ('Mean Absoloute Error for ',estMethod,' : ', MAE)\n",
    "\n",
    "def print_most_similar_jokes(dataMat, jokes, queryJoke, k, metric=pearsSim):\n",
    "\t# Write this function to find the k most similar jokes (based on user ratings) to a queryJoke\n",
    "\t# The queryJoke is a joke id as given in the 'jokes.csv' file (an corresponding to the a column in dataMat)\n",
    "\t# You must compare ratings for the queryJoke (the column in dataMat corresponding to the joke), to all\n",
    "\t# other joke rating vectors and return the top k. Note that this is the same as performing KNN on the \n",
    "    # columns of dataMat. The function must retrieve the text of the joke from 'jokes.csv' file and print both\n",
    "\t# the queryJoke text as well as the text of the returned jokes.\n",
    "\n",
    "    def load_jokes(file):\n",
    "        jokes = genfromtxt(file, delimiter=',', dtype=str)\n",
    "        jokes = np.array(jokes[:,1])\n",
    "        return jokes\n",
    "\n",
    "def get_joke_text(jokes, id):\n",
    "\treturn jokes[id]\n",
    "\n",
    "# dataMat = genfromtxt('modified_jester_data.csv',delimiter=',')\n",
    "\n",
    "# test(dataMat, 0.2, svdEst)\n",
    "# test(dataMat, 0.2, standEst)\n",
    "\n",
    "# jokes = load_jokes('jokes.csv')\n",
    "# print_most_similar_jokes(dataMat, jokes, 3, 5, pearsSim)\n",
    "\n",
    "''' See example output below:\n",
    "\n",
    "Selected joke: \n",
    "\n",
    "Q. What's the difference between a man and a toilet? A. A toilet doesn't follow you around after you use it.\n",
    "\n",
    "Top 5 Recommended jokes are :\n",
    "\n",
    "Q: What's the difference between a Lawyer and a Plumber? A: A Plumber works to unclog the system. \n",
    "_______________\n",
    "What do you call an American in the finals of the world cup? \"Hey Beer Man!\" \n",
    "_______________\n",
    "Q. What's 200 feet long and has 4 teeth? <P>A. The front row at a Willie Nelson Concert. \n",
    "_______________\n",
    "A country guy goes into a city bar that has a dress code and the maitred' demands he wear a tie. Discouraged the guy goes to his car to sulk when inspiration strikes: He's got jumper cables in the trunk! So he wrapsthem around his neck sort of like a string tie (a bulky string tie to be sure) and returns to the bar. The maitre d' is reluctant but says to the guy \"Okay you're a pretty resourceful fellow you can come in... but just don't start anything\"!   \n",
    "_______________\n",
    "What do you get when you run over a parakeet with a lawnmower? <P>Shredded tweet. \n",
    "_______________\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Complete the definition for the function \"test\". This function iterates over all users and for each performs evaluation (by calling the provided \"cross_validate_user\" function), and returns the error information necessary to compute Mean Absolute Error (MAE). Use this function to perform evaluation (wiht 20% test-ratio for each user) comparing MAE results using standard item-based collaborative filtering (based on the rating prediction function \"standEst\") with results using the SVD-based version of the rating item-based CF (using \"svdEst\" as the prediction engine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataMat, test_ratio, estMethod):\n",
    "    # Write this function to iterate over all users and for each perform cross-validation on items by calling\n",
    "    # the above cross-validation function on each user.\n",
    "    # MAE will be the ratio of total error across all test cases to the total number of test cases, for all users\n",
    "    \n",
    "    #row = dataMat[0,]\n",
    "    #print \"A row is: \", row\n",
    "    total_error=0.0\n",
    "    total_count=0\n",
    "    for user in range(dataMat.shape[0]):\n",
    "        error, count = cross_validate_user(dataMat, user, .2, estMethod)\n",
    "        total_error = total_error + error\n",
    "        total_count = total_count + count\n",
    "    MAE = total_error/total_count\n",
    "    print ('Mean Absoloute Error for ',estMethod,' : ', MAE)\n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-0334ffb0eb3d>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(dataMat, test_ratio, estMethod)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtotal_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataMat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validate_user\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataMat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestMethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mtotal_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_error\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mtotal_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_count\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-cc430dc50e68>\u001b[0m in \u001b[0;36mcross_validate_user\u001b[1;34m(dataMat, user, test_ratio, estMethod, simMeas)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mrated_items_by_user\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_of_items\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdataMat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_ratio\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrated_items_by_user\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mtest_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrated_items_by_user\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[0mwithheld_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrated_items_by_user\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0moriginal_user_profile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataMat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int32\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test(ratings, .2, standEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNearestNeighbors(inX, dataSet, k, measure):\n",
    "    distances = []\n",
    "    for i in range(dataSet.shape[1]):\n",
    "        vector = dataSet[:,i]\n",
    "        distance = measure(inX, vector)\n",
    "        distances.append(distance)\n",
    "    #print \"Before, distances is: \", distances\n",
    "    distancesArray = np.array(distances)\n",
    "    #print \"After, distances is: \", distancesArray\n",
    "    sortedDistIndicies = distancesArray.argsort()\n",
    "    kNeighbors = zeros((k,dataSet.shape[1]))\n",
    "    topIndicies = []\n",
    "    classCount={}\n",
    "    for i in range(k):\n",
    "        #voteIlabel = labels[sortedDistIndicies[i]]\n",
    "        kNeighbors[i,:] = dataSet[sortedDistIndicies[i],:]\n",
    "        topIndicies.append(sortedDistIndicies[i])\n",
    "        #print \"sortedDistIndices: is\", sortedDistIndicies\n",
    "        #print \"kNeighbors is: \", kNeighbors\n",
    "        #classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1\n",
    "    #sortedClassCount = sorted(classCount.iteritems(),key=operator.itemgetter(1), reverse=True)\n",
    "    return kNeighbors, topIndicies  #, sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Write a new function \"print_most_similar_jokes\" which takes the joke ratings data, a query joke id, a parameter k for the number of nearest neighbors, and a similarity metric function, and prints the text of the query joke as well as the texts of the top k most similar jokes based on user ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_most_similar_jokes(dataMat, jokes, queryJoke, k, metric=pearsSim):\n",
    "    # Write this function to find the k most similar jokes (based on user ratings) to a queryJoke\n",
    "    # The queryJoke is a joke id as given in the 'jokes.csv' file (an corresponding to the a column in dataMat)\n",
    "    # You must compare ratings for the queryJoke (the column in dataMat corresponding to the joke), to all\n",
    "    # other joke rating vectors and return the top k. Note that this is the same as performing KNN on the \n",
    "    # columns of dataMat. The function must retrieve the text of the joke from 'jokes.csv' file and print both\n",
    "    # the queryJoke text as well as the text of the returned jokes.\n",
    "    queryJokeVector = dataMat[:,queryJoke]\n",
    "    print (\"Selcted joke: \")\n",
    "    print()\n",
    "    print (jokes[queryJoke])\n",
    "    print()\n",
    "    dataMatArray = np.array(dataMat)\n",
    "    knn, indicies = kNearestNeighbors(queryJokeVector, dataMat, k, metric)\t\n",
    "    print (\"The top %d recommended jokes are: \"%(k))\n",
    "    for ind in indicies:\n",
    "        jok = jokes[ind]\n",
    "        print()\n",
    "        print (jok)\n",
    "    #print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selcted joke: \n",
      "\n",
      "Q. What's the difference between a man and a toilet? A. A toilet doesn't follow you around after you use it.\n",
      "\n",
      "The top 5 recommended jokes are: \n",
      "\n",
      "A dog walks into Western Union and asks the clerk to send a telegram. He fills out a form on which he writes down the telegram he wishes to send: \"Bow wow wow Bow wow wow.\"The clerk says \"You can add another 'Bow wow' for the same price.\"The dog responded \"Now wouldn't that sound a little silly?\"\n",
      "\n",
      "Q:  What did the blind person say when given some matzah?A:  Who the hell wrote this?\n",
      "\n",
      "Q. Did you hear about the dyslexic devil worshipper? A. He sold his soul to Santa.\n",
      "\n",
      "Q. What is orange and sounds like a parrot?  A. A carrot.\n",
      "\n",
      "A guy goes into confession and says to the priest \"Father I'm 80 years old widower with 11 grandchildren. Last night I met two beautiful flight attendants. They took me home and I made love to both of them. Twice.\"The priest said: \"Well my son when was the last time you were in confession?\" \"Never Father I'm Jewish.\" \"So then why are you telling me?\" \"I'm telling everybody.\"\n"
     ]
    }
   ],
   "source": [
    "print_most_similar_jokes(ratings, jokes, 3, 5, pearsSim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
